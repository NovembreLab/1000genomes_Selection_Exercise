# Understanding Natural Selection from Population Genomic Data

* still in progress (not tested). 
* using Duffy as an example (http://www.snpedia.com/index.php/Rs2814778)
* description / writing needs to be filled in 

## 1. Setting up your Enviroment 

### 1.1 Downloading and Building Methods

#### Download

```bash
cd src/

# download tabix
git clone https://github.com/samtools/tabix

# download htslib & bcftools
wget http://sourceforge.net/projects/samtools/files/samtools/1.2/htslib-1.2.1.tar.bz2
wget http://sourceforge.net/projects/samtools/files/samtools/1.2/bcftools-1.2.tar.bz2

# clone selscan
git clone -b devel https://github.com/szpiech/selscan

# download plink (double check that the correct OS is specified)
wget https://www.cog-genomics.org/static/bin/plink150602/plink_linux_x86_64_dev.zip
```

#### Build

```bash
# tabix
cd tabix/
make
mv tabix ../../bin/

# bcftools
cd ../
tar xvjf htslib-1.2.1.tar.bz2
tar xvjf bcftools-1.2.tar.bz2
cd bcftools-1.2/
make
mv bcftools ../../bin/

# plink
cd ../
mkdir plink
unzip plink_linux_x86_64_dev.zip -d plink
mv plink/plink ../bin

# selscan
cd selscan/

# open Makefile make sure the correct OS is specified 
cd src/ 
make
mv norm ../../../bin/
mv selscan ../../../bin/

# lets go home
cd ../../../
ls bin/

# you should see binaries for tabix, bcftools, plink, selscan, and norm

# export path 
export PATH=path_to_SSW_2015_dir/bin:$PATH
```

### 1.2 Downloading Data

#### 1000genomes_phase3

```bash
cd data/

# download and filter a 2MB region (1:158000000-162000000) from the 1000genomes project. Sometimes the ftp goes down if you get an error try running the command again.
tabix -h ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/release/20130502/ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz 1:158000000-162000000 | bgzip -c > 1000genomes_phase3_chr1_158000000_162000000.vcf.gz

# download 1000genomes_phase3 individual information
wget ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/release/20130502/integrated_call_samples_v3.20130502.ALL.panel
```

### 1.3 Filtering Data and QC

#### Preparing CLST / IID Files 

```bash
# remove the first line and format file as IID | IID | CLST for YRI, CEU, and CHB
sed '1d' integrated_call_samples_v3.20130502.ALL.panel | awk '{if($2 == "YRI" || $2 == "CEU" || $2 == "CHB") print $1, $1, $2}' > yri_ceu_chb_clst.txt

# write a file of just IIDs 
awk '{print $1}' yri_ceu_chb_clst.txt > yri_ceu_chb_iids.txt

# write a clst file for just YRI and CEU
awk '{if($3 == "YRI" || $3 == "CEU") print $0}' yri_ceu_chb_clst.txt > yri_ceu_clst.txt

# write a clst file for just YRI and CHB 
awk '{if($3 == "YRI" || $3 == "CHB") print $0}' yri_ceu_chb_clst.txt > yri_chb_clst.txt

# write a clst file for just CEU and CHB
awk '{if($3 == "CEU" || $3 == "CHB") print $0}' yri_ceu_chb_clst.txt > ceu_chb_clst.txt

# write a file of just IIDs from YRI 
awk '{if($3 == "YRI") print $1}' yri_ceu_chb_clst.txt > yri_iids.txt

# check if # individuals are correct
wc -l yri_ceu_chb_iids.txt yri_ceu_clst.txt yri_chb_clst.txt ceu_chb_clst.txt yri_iids.txt
```

#### Preparing Genomic Data

```bash
# filter out indels (-V indels), multi-allelic sites (-m 2 -M 2), and keep individuals (-S) from YRI, CEU, CHB 
# this will be used for cross-population based selection analysis
bcftools view -V indels -m 2 -M 2 -S yri_ceu_chb_iids.txt -O z 1000genomes_phase3_chr1_158000000_162000000.vcf.gz > yri_ceu_chb_chr1_158000000_162000000_filtered.vcf.gz

# keep YRI individuals from the filtered vcf
# this will be used for haplotype based selection analysis.
bcftools view -S yri_iids.txt -O z yri_ceu_chb_chr1_chr1_158000000_162000000_filtered.vcf.gz > yri_chr1_chr1_158000000_162000000_filtered.vcf.gz

# write bim file from vcf (-H supress header)
bcftools view yri_chr1_158000000_162000000_filtered.vcf.gz -H | awk '{print $1, $3, "0", $2, $4, $5}' > chr1_158000000_162000000_filtered.bim

# get genetic positions and interpolate genetic positions for variants not present in the genetic_map
plink --bim chr1_158000000_162000000_filtered.bim \
      --cm-map genetic_map_chr1_combined_b37.txt 1 \
      --make-just-bim \
      --out chr1_158000000_162000000_filtered_gm

# format as map file
awk '{print $1, $2, $3, $4}' chr1_158000000_162000000_filtered_gm.bim > chr1_158000000_162000000_filtered_gm.map 
```

### Questions

## 2. Computing Selection Statistics 

### 2.1 Fst

```bash
# Fst between YRI and CEU
plink --vcf yri_ceu_chb_chr1_158000000_162000000_filtered.vcf.gz \
      --fst \
      --within yri_ceu_clst.txt \
      --double-id \
      --id-delim . \
      --out yri_ceu_chr1_158000000_162000000_filtered \
      --set-missing-var-ids @:#
     
# Fst between YRI and CHB
plink --vcf yri_ceu_chb_chr1_158000000_162000000_filtered.vcf.gz \
      --fst \
      --within yri_chb_clst.txt \
      --double-id \
      --id-delim . \
      --out yri_chb_chr1_158000000_162000000_filtered \
      --set-missing-var-ids @:#
             
# Fst between CEU and CHB
plink --vcf yri_ceu_chb_chr1_158000000_162000000_filtered.vcf.gz \
      --fst \
      --within ceu_chb_clst.txt \
      --double-id \
      --id-delim . \
      --out ceu_chb_chr1_158000000_162000000_filtered \
      --set-missing-var-ids @:#
```

### 2.2. PBS

Not sure if PBS that useful for this example unless were intersted in frequency change accumlated in YRI branch since out of Africa?

$$ T = -log(1 - Fst) $$
$$ PBS = \frac{T_{YRI,CEU} + T_{YRI,CHB} - T_{CEU,CHB}}{2} $$

```R
library(dplyr)

fst_yri_ceu_df <- read.table('yri_ceu_chr1_158000000_162000000_filtered.fst', header = TRUE)
fst_yri_chb_df <- read.table('yri_chb_chr1_158000000_162000000_filtered.fst', header = TRUE)
fst_ceu_chb_df <- read.table('ceu_chb_chr1_158000000_162000000_filtered.fst', header = TRUE)

# bug - too many nans
pbs_df <- data.frame(CHR = fst_yri_ceu_df$CHR, SNP=fst_yri_ceu_df$SNP, POS=fst_yri_ceu_df$POS,
                     NMISS = fst_yri_ceu_df$NMISS, YRI_CEU_FST = fst_yri_ceu_df$FST, 
                     YRI_CHB_FST = fst_yri_chb_df$FST, CEU_CHB_FST = fst_ceu_chb_df$FST)
```

### 2.3 iHS

this region might be too big (i.e. too slow for the workshop) perhaps a more stringent maf filter would be reasonable? 

```bash
# compute iHS! This will take about 10 minutes
selscan --ihs \
        --vcf yri_chr1_158000000_162000000_filtered.vcf.gz \
        --map chr1_158000000_162000000_filtered_gm.map \
        --out yri_ceu_chb_chr1_158000000_162000000_filtered   
```

### 2.4 nSL (maybe if there is time)

### 2.4 Visualization 

### Questions

## 3. Assesing Significance 

### 3.1 Genome(Region)-Wide Null Distribution

```
norm --ihs --files yri_ceu_chb_chr1_158000000_162000000filtered.ihs.out
```

### 3.2 Simulating a Null Model

### 3.3 Visualization 


```r
library(ggplot2)
library(dplyr)
```

```
## 
## Attaching package: 'dplyr'
## 
## The following object is masked from 'package:stats':
## 
##     filter
## 
## The following objects are masked from 'package:base':
## 
##     intersect, setdiff, setequal, union
```

```r
ihs_path <- "~/jhmarcus/Teaching/SSW_2015/dev/data/yri_ceu_chb_chr1_158000000_162000000filtered.ihs.out.100bins.norm"
ihs_df <- read.table(ihs_path, header=FALSE)
```

```
## Warning: cannot open file
## '/mnt/lustre/home/jhmarcus/jhmarcus/Teaching/SSW_2015/dev/data/yri_ceu_chb_chr1_158000000_162000000filtered.ihs.out.100bins.norm':
## No such file or directory
```

```
## Error: cannot open the connection
```

```r
colnames(ihs_df) <- c("locusID", "physicalPos", "freq", "ihh1", "ihh0", "unstandardized_iHS",
                       "standardized_iHS", "top")
```

```
## Error: object 'ihs_df' not found
```

```r
ihs_top_01_percent <- quantile(abs(ihs_df$standardized_iHS), c(.99)) 
```

```
## Error: object 'ihs_df' not found
```

```r
p <- ggplot(ihs_df, aes(x = physicalPos, y = abs(standardized_iHS))) + geom_point() + 
     geom_hline(yintercept = ihs_top_01_percent) + ylab("|standardized_iHS|") + xlab("Position") + 
     theme_bw()
```

```
## Error: object 'ihs_df' not found
```

```r
print(p)
```

```
## Error: object 'p' not found
```

### 3.4 Spandrels of San Marco (Caveats)

### Questions 

## 4. References








